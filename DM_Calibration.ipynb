{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"/Users/dsaha/Python/alpao_calibration\")\n",
    "from calibration import Calibration\n",
    "%matplotlib inline\n",
    "import json\n",
    "from scipy.spatial.distance import cdist\n",
    "mirror = Calibration()\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Name = {0: 'ObliqueAstigmation', 1: 'Defocus', 2: 'VerticalAstigmation', 3: 'VerticalTrefoil', 4: 'VerticalComa', 5: 'ObliqueTrefoil'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/Acquisition/20180205_Random_10000.txt\")\n",
    "actuators = dataset[:,:97]\n",
    "zernikes = dataset[:,100:]\n",
    "\n",
    "#dataset = np.loadtxt(\"/Users/dsaha/Desktop/calibration_measurement_random_2000.txt\")\n",
    "#actuators1 = dataset[:, :97]\n",
    "#zernikes1 = dataset[:, 97:]\n",
    "\n",
    "#np.savetxt(\"/Users/dsaha/Desktop/TrialActuatorsNew_1.txt\" , actuators[1,:].reshape(1,97), delimiter=\",\")\n",
    "#np.savetxt(\"/Users/dsaha/Desktop/TrialActuatorsOld.txt\" , new, delimiter=\",\")\n",
    "#print(\"New Zernikes\" + str(zernikes[1,:]))\n",
    "#print(\"Old Zernikes\" + str(zernikes1[0,:]))\n",
    "#np.mean(actuators,axis=-1)\n",
    "#print(np.std(zernikes,axis=1))\n",
    "#plt.hist(actuators.flatten(),50);\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.hist(zernikes.flatten(),50);\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.hist(zernikes1.flatten(),50);\n",
    "\n",
    "#np.min(zernikes)\n",
    "#plt.figure(figsize=(10,7))\n",
    "#plt.subplot(2,3,1)\n",
    "#mirror.plot_acc(actuators[1,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,3,2)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes[1,:])], axis = 0))\n",
    "#plt.axis('off')\n",
    "#plt.subplot(2,3,3)\n",
    "#plt.bar(range(0,66),zernikes[1,:])\n",
    " \n",
    "#plt.subplot(2,3,4)\n",
    "#mirror.plot_acc(actuators1[100,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,3,5)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes1[100,:])], axis = 0))\n",
    "#plt.axis('off')\n",
    "#plt.subplot(2,3,6)\n",
    "#plt.bar(range(0,66),zernikes1[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#da = cdist(actuators,actuators1)\n",
    "#dz = cdist(zernikes[:,3:],zernikes1[:,3:])\n",
    "#plt.hist(dz.flatten(),50);\n",
    "#dz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(np.where(da<0.27))\n",
    "#print(dz[4774,1385])\n",
    "#print(np.min(dz))\n",
    "#print(np.where(dz<0.1767))\n",
    "#dz[9510,1212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.subplot(2,2,1)\n",
    "#mirror.plot_acc(actuators[4774,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes[4774,3:])], axis = 0))\n",
    "#plt.axis('off') \n",
    "#plt.subplot(2,2,3)\n",
    "#mirror.plot_acc(actuators1[1385,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes1[1385,3:])], axis = 0))\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "#plt.subplot(2,2,1)\n",
    "#plt.plot(zernikes[4774,3:])\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.plot(actuators[4774,:])\n",
    "#plt.subplot(2,2,3)\n",
    "#plt.plot(zernikes1[1385,3:])\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.plot(actuators1[1385,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.subplot(2,2,1)\n",
    "#mirror.plot_acc(actuators[9510,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes[9510,3:])], axis = 0))\n",
    "#plt.axis('off') \n",
    "#plt.subplot(2,2,3)\n",
    "#mirror.plot_acc(actuators1[1212,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes1[1212,3:])], axis = 0))\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "#plt.subplot(2,2,1)\n",
    "#plt.plot(zernikes[9510,:])\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.plot(actuators[9510,:])\n",
    "#plt.subplot(2,2,3)\n",
    "#plt.plot(zernikes1[1212,:])\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.plot(actuators1[1212,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#actuators.shape, zernikes.shape\n",
    "#print(np.min(actuators),np.max(actuators))\n",
    "#print(np.min(actuators1),np.max(actuators1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(63,))\n",
    "\n",
    "lay = Dense(64, activation=\"tanh\")(inp)\n",
    "\n",
    "#for _ in range(3):\n",
    "#    lay = Dense(128, activation=\"sigmoid\")(lay)\n",
    "    \n",
    "oup = Dense(97)(lay)\n",
    "#oup = Dense(97)(inp)\n",
    "m = Model(inp,oup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 63)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 97)                6305      \n",
      "=================================================================\n",
      "Total params: 10,401\n",
      "Trainable params: 10,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.compile(Adam(lr=0.0004),'mse')\n",
    "#m.compile(loss='mean_squared_logarithmic_error',optimizer=Adam(0.0004))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "9000/9000 [==============================] - 1s 100us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 2/200\n",
      "9000/9000 [==============================] - 1s 94us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 3/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 4/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 6/200\n",
      "9000/9000 [==============================] - 1s 77us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 7/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 9/200\n",
      "9000/9000 [==============================] - 1s 82us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "9000/9000 [==============================] - 1s 108us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 11/200\n",
      "9000/9000 [==============================] - 1s 91us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "9000/9000 [==============================] - 1s 77us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/200\n",
      "9000/9000 [==============================] - 1s 81us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 20/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 23/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 24/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 25/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 26/200\n",
      "9000/9000 [==============================] - 1s 71us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 27/200\n",
      "9000/9000 [==============================] - 1s 90us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 28/200\n",
      "9000/9000 [==============================] - 1s 93us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 29/200\n",
      "9000/9000 [==============================] - 1s 87us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 30/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 31/200\n",
      "9000/9000 [==============================] - 1s 98us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 32/200\n",
      "9000/9000 [==============================] - 1s 86us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 34/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 36/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 37/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 39/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 40/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 41/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 42/200\n",
      "9000/9000 [==============================] - 1s 87us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 43/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 44/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 45/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 46/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 47/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 48/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 49/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 50/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 51/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 52/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 53/200\n",
      "9000/9000 [==============================] - 1s 83us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 54/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 55/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 56/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 57/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 58/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 59/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 60/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 61/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 62/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 63/200\n",
      "9000/9000 [==============================] - 1s 115us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "9000/9000 [==============================] - 1s 111us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "9000/9000 [==============================] - 1s 85us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "9000/9000 [==============================] - 1s 89us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 68/200\n",
      "9000/9000 [==============================] - 1s 94us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 69/200\n",
      "9000/9000 [==============================] - 1s 87us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 70/200\n",
      "9000/9000 [==============================] - 1s 92us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 71/200\n",
      "9000/9000 [==============================] - 1s 106us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 72/200\n",
      "9000/9000 [==============================] - 1s 102us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 73/200\n",
      "9000/9000 [==============================] - 1s 95us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 74/200\n",
      "9000/9000 [==============================] - 1s 83us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 75/200\n",
      "9000/9000 [==============================] - 1s 103us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 76/200\n",
      "9000/9000 [==============================] - 1s 97us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 77/200\n",
      "9000/9000 [==============================] - 1s 85us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 78/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 79/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 80/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 81/200\n",
      "9000/9000 [==============================] - 1s 82us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 82/200\n",
      "9000/9000 [==============================] - 1s 117us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 83/200\n",
      "9000/9000 [==============================] - 1s 98us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 84/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 85/200\n",
      "9000/9000 [==============================] - 1s 107us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 86/200\n",
      "9000/9000 [==============================] - 1s 101us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 87/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 88/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 89/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 90/200\n",
      "9000/9000 [==============================] - 1s 86us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 91/200\n",
      "9000/9000 [==============================] - 1s 85us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 92/200\n",
      "9000/9000 [==============================] - 1s 99us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 93/200\n",
      "9000/9000 [==============================] - 1s 106us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 94/200\n",
      "9000/9000 [==============================] - 1s 106us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 95/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 96/200\n",
      "9000/9000 [==============================] - 1s 96us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 97/200\n",
      "9000/9000 [==============================] - 1s 97us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 98/200\n",
      "9000/9000 [==============================] - 1s 81us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 99/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 100/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 101/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 102/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 103/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 104/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 105/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 106/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 107/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 108/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 109/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 110/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 111/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 112/200\n",
      "9000/9000 [==============================] - 1s 81us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 113/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 114/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 115/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 116/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 117/200\n",
      "9000/9000 [==============================] - 1s 87us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 118/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 119/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 120/200\n",
      "9000/9000 [==============================] - 1s 85us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 121/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 122/200\n",
      "9000/9000 [==============================] - 3s 367us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 123/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 124/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 125/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 126/200\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 127/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 128/200\n",
      "9000/9000 [==============================] - 1s 81us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 129/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 130/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 131/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 132/200\n",
      "9000/9000 [==============================] - 1s 107us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 133/200\n",
      "9000/9000 [==============================] - 1s 97us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 134/200\n",
      "9000/9000 [==============================] - 1s 98us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 135/200\n",
      "9000/9000 [==============================] - 1s 101us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 136/200\n",
      "9000/9000 [==============================] - 1s 91us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 137/200\n",
      "9000/9000 [==============================] - 1s 82us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 138/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 139/200\n",
      "9000/9000 [==============================] - 1s 82us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 140/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 141/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 142/200\n",
      "9000/9000 [==============================] - 1s 84us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 143/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 144/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 145/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 146/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 147/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 148/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 149/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 150/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 151/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 152/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 153/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 154/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 156/200\n",
      "9000/9000 [==============================] - 1s 85us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 157/200\n",
      "9000/9000 [==============================] - 1s 98us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 158/200\n",
      "9000/9000 [==============================] - 1s 86us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 159/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 160/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 161/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 162/200\n",
      "9000/9000 [==============================] - 1s 77us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 163/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 164/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 165/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 166/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 167/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 168/200\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 169/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 170/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 171/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 172/200\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 173/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 174/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 175/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 176/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 177/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 178/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 179/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 180/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 181/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 182/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 183/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 184/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 185/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 186/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 187/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 188/200\n",
      "9000/9000 [==============================] - 1s 77us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 189/200\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 190/200\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 191/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 192/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 193/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 194/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 195/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 196/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 197/200\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 198/200\n",
      "9000/9000 [==============================] - 1s 76us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 199/200\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 200/200\n",
      "9000/9000 [==============================] - 1s 77us/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "hist = m.fit(zernikes,actuators,batch_size=10,epochs=200, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d25ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#flat = np.zeros((1,63))\n",
    "##Defocus is 5-4 = 1, Astigmation X is 4-4=0, Astigmation Y is 6-4=2\n",
    "field_generate = np.zeros((1,63))\n",
    "field_generate = field_generate.reshape((1,63))\n",
    "field_generate[0,4] = +0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=m.predict(field_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trial=m.predict(zernikes)\n",
    "#trialdist = cdist(actuators,trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11a6ab588>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAACFCAYAAADW1wrTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e9e4550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,2,1)\n",
    "mirror.plot_acc(a, cmap = \"coolwarm\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.sum([_z*mirror.zern_modes[i+3] for i,_z in enumerate(field_generate.T)], axis = 0))\n",
    "#plt.axis('off') \n",
    "#plt.subplot(2,2,3)\n",
    "#mirror.plot_acc(trial[0,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes[0,:])], axis = 0))\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Text file save\n",
    "now = datetime.datetime.now()\n",
    "os.mkdir(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/%s\"%now)\n",
    "modes_of_zern = np.array([0,1,2,3,4,5])\n",
    "values = np.arange(-0.2,0.2,0.01)\n",
    "for i in modes_of_zern:\n",
    "    for j in values:\n",
    "        field_generate = np.zeros((1,63))\n",
    "        field_generate = field_generate.reshape((1,63))\n",
    "        field_generate[0,i] = j\n",
    "        a=m.predict(field_generate)\n",
    "        np.savetxt(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/%s/%s_%f.txt\" %(now,Name[i],j), a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Json file save\n",
    "now = datetime.datetime.now()\n",
    "os.mkdir(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/%s\"%now)\n",
    "modes_of_zern = np.array([1])\n",
    "values = np.arange(-0.1,0.1,0.01)\n",
    "for i in modes_of_zern:\n",
    "    for j in values:\n",
    "        field_generate = np.zeros((1,63))\n",
    "        field_generate = field_generate.reshape((1,63))\n",
    "        field_generate[0,i] = j\n",
    "        a=m.predict(field_generate)\n",
    "        act = np.zeros((11,11))\n",
    "        count = 0;\n",
    "        for k in range(0,11):\n",
    "             for l in range(0,11):\n",
    "                if k+l<=2:\n",
    "                    continue\n",
    "                elif k+l>=18:\n",
    "                    continue\n",
    "                elif abs(k-l)>=8:\n",
    "                    continue\n",
    "                else:\n",
    "                    act[k,l] = a[0,count]\n",
    "                count = count+1\n",
    "\n",
    "        ac = act.tolist()\n",
    "        filepath = open(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/%s/%s_%f.json\" %(now,Name[i],j),'w+')\n",
    "        json.dump(ac,filepath)\n",
    "        filepath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "#plt.plot(trial[0])\n",
    "#plt.plot(a2[0])\n",
    "#plt.plot(a3[0],\"r\")\n",
    "#plt.plot(actuators[0], \"k:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.hist(trialdist.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mirror = Calibration() \n",
    "#plt.subplot(2,2,1)\n",
    "#mirror.plot_acc(a3, cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(flat.T)], axis = 0))\n",
    "#plt.axis('off')\n",
    "#plt.subplot(2,2,3)\n",
    "#mirror.plot_acc(a, cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(flat.T)], axis = 0))\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = np.zeros((11,11))\n",
    "count = 0;\n",
    "for i in range(0,11):\n",
    "     for j in range(0,11):\n",
    "        if i+j<=2:\n",
    "            continue\n",
    "        elif i+j>=18:\n",
    "            continue\n",
    "        elif abs(i-j)>=8:\n",
    "            continue\n",
    "        else:\n",
    "            act[i,j] = a[0,count]\n",
    "            count = count+1\n",
    "\n",
    "ac = act.tolist()\n",
    "#filepath = open(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/NeuronalNetworkResult/AstigmationOblique.json\",'w+')\n",
    "filepath = open(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/Test.json\",'w+')\n",
    "json.dump(ac,filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.20939000e-01,  -2.19225000e-01,  -1.21552000e-01,\n",
       "         6.22660000e-02,   5.59000000e-03,   4.96400000e-03,\n",
       "        -2.72480000e-02,   4.99070000e-02,   3.69300000e-02,\n",
       "         6.42750000e-02,   2.70120000e-02,   2.86800000e-03,\n",
       "         7.10500000e-03,   7.00400000e-03,   7.85600000e-03,\n",
       "         2.35540000e-02,  -1.24700000e-03,   3.23910000e-02,\n",
       "         4.20580000e-02,  -2.83260000e-02,  -2.25070000e-02,\n",
       "         4.90000000e-05,  -1.93040000e-02,   3.89200000e-03,\n",
       "        -1.16270000e-02,   2.81180000e-02,  -9.25400000e-03,\n",
       "        -1.20910000e-02,  -1.50800000e-02,  -1.72120000e-02,\n",
       "         5.50000000e-03,  -1.87980000e-02,  -7.68000000e-03,\n",
       "        -1.40350000e-02,  -2.30400000e-03,   4.14000000e-03,\n",
       "         7.09600000e-03,  -1.15570000e-02,   1.24630000e-02,\n",
       "        -6.93800000e-03,   1.52290000e-02,  -9.05400000e-03,\n",
       "         4.05900000e-03,  -1.10740000e-02,   7.80600000e-03,\n",
       "         7.52300000e-03,   6.10700000e-03,  -2.55000000e-04,\n",
       "        -2.54400000e-03,   6.40000000e-03,   6.45500000e-03,\n",
       "        -8.11000000e-04,  -4.45900000e-03,   8.69200000e-03,\n",
       "        -4.38400000e-03,   1.30600000e-03,  -5.57200000e-03,\n",
       "         8.96200000e-03,   6.77000000e-04,   2.55400000e-03,\n",
       "        -5.95400000e-03,  -2.53100000e-03,  -2.81900000e-03])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.savetxt(\"/Users/dsaha/Desktop/Neuronal_Defocus.txt\" , a, delimiter=\",\")\n",
    "zernikes[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/Test.txt\" , a, delimiter=\",\")\n",
    "#np.savetxt(\"/Volumes/Debayan/Calibration_data_Alpao_BScope/GenerateAberrationModes_Neuonal/Flat20180131.txt\" , a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "#plt.plot(a[0])\n",
    "#plt.plot(a2[0])\n",
    "#plt.plot(a3[0],\"r\")\n",
    "#plt.plot(actuators[0], \"k:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.subplot(2,2,1)\n",
    "#plt.plot(a3[0])\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.plot(actuators[0], \"k:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#M2 = m.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "#plt.imshow(M, cmap = \"magma\")\n",
    "#plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#da = cdist(actuators,actuators)\n",
    "#dz = cdist(zernikes,zernikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.hist(dz.flatten(),50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x1,x2 = np.where(dz<0.3)\n",
    "#print(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.hist(dz[dz>0].flatten(),50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delta = da/(dz+.0001)\n",
    "#print(da[1130,1132]/dz[1130,1132])\n",
    "#plt.hist(delta.flatten(),50);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i1,i2 = np.where(delta>1.4)\n",
    "#i1.size\n",
    "#print(i1,i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i1,i2 = np.where(np.bitwise_and(dz>0,dz<0.25))\n",
    "#i1.size\n",
    "#print(i1,i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n = 0\n",
    "#mirror = Calibration() \n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.subplot(2,2,1)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes[0,:])], axis = 0))\n",
    "#plt.axis(\"off\")\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.imshow(np.sum([_z*mirror.zern_modes[i] for i,_z in enumerate(zernikes1[991,:])], axis = 0))\n",
    "#plt.axis(\"off\")\n",
    "#plt.subplot(2,2,3)\n",
    "#mirror.plot_acc(actuators[0,:], cmap = \"coolwarm\")\n",
    "#plt.subplot(2,2,4)\n",
    "#mirror.plot_acc(actuators1[991,:], cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i1, i2 =np.unravel_index(np.argmax(delta), delta.shape)\n",
    "#print(i1,i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a1, a2 = actuators[i1], actuators[i2]\n",
    "#z1, z2 = zernikes[i1], zernikes[i2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(zernikes[0,:])\n",
    "#plt.plot(zernikes1[991,:])\n",
    "#print(np.sum((zernikes[0,:] - zernikes1[991,:])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(z1[3])\n",
    "#plt.plot(z2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(a1)\n",
    "#plt.plot(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(zernikes[580])\n",
    "#plt.plot(zernikes[1576])\n",
    "#plt.plot(zernikes[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(actuators[1130])\n",
    "#plt.plot(actuators[1131])\n",
    "#plt.plot(actuators[1132])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
